{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from os import listdir,path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswahl Bilder-Pfad\n",
    "img_path = './shared_images/'\n",
    "img_files = listdir(img_path)\n",
    "len(img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ansicht eines Beispielbildes\n",
    "img_example = cv2.imread(img_path + img_files[10])\n",
    "plt.imshow(img_example)\n",
    "print(img_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen aller Bilder -> Kontrolle der Anzahl\n",
    "imgs = np.array([cv2.imread(img_path+i) for i in img_files])\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittleres Bilder der Trainingsbilder\n",
    "img_mean = imgs.mean(axis=0).astype('int')\n",
    "plt.imshow(img_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testweise Bildbearbeitung\n",
    "# Definition Fenster, Graufärbung und Größenänderung\n",
    "sp=(0,200)\n",
    "ep=(320,100)\n",
    "dim = (320,240)\n",
    "interpolation = cv2.INTER_AREA\n",
    "img_example_x = img_example.copy()\n",
    "img_example_x = cv2.cvtColor(img_example_x,cv2.COLOR_BGR2GRAY)\n",
    "img_example_x= cv2.resize(img_example_x,dim,interpolation)\n",
    "plt.imshow(cv2.rectangle(img_example_x,sp,ep,(255,255,0),2),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition einer Funktion zur Vorverarbeitung eines einzelnen Trainingsbildes\n",
    "# Dieser Verarbeitungsschritte müssen bei der Anwendungung des neuronlen Netzes\n",
    "# am RPi ebenfalls in identischer Form durchgeführt werden.\n",
    "def transform_image(img):\n",
    "    dim = (320,240)\n",
    "    interpolation = cv2.INTER_AREA\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # Verwendung von Graustufenbildern\n",
    "    img = cv2.resize(img,dim,interpolation) #  Anpassung der Bildgröße\n",
    "    img = img[100:200,:] # Ausschneiden eines Teilbildes\n",
    "    return img\n",
    "\n",
    "plt.imshow(transform_image(imgs[0]),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative mit Verkleinerung der Bilder\n",
    "# Definition einer Funktion zur Vorverarbeitung der Trainingsbilder\n",
    "def transform_image_small(img):\n",
    "    dim = (64,48)\n",
    "    interpolation = cv2.INTER_AREA\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # Verwendung von Graustufenbildern\n",
    "    img = cv2.resize(img,dim,interpolation) #  Anpassung der Bildgröße\n",
    "    img = img[20:40,:] # Ausschneiden eines Teilbildes\n",
    "    return img\n",
    "\n",
    "plt.imshow(transform_image_small(imgs[0]),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden und Vorverarbeiten aller Trainingsbilder (groß)\n",
    "imgs_large = np.array([transform_image(cv2.imread(img_path+i)) for i in img_files])\n",
    "imgs_large.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden und Vorverarbeiten aller Trainingsbilder (klein)\n",
    "imgs_small = np.array([transform_image_small(cv2.imread(img_path+i)) for i in img_files])\n",
    "imgs_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position des Lenkwinkels im Filenamen (abhängig von gewählter Vorgehensweise)\n",
    "x = img_files[0]\n",
    "print(x)\n",
    "print('-',x[-7:-4],'-') # Raspberry/Linux\n",
    "print('-',x[50:-4],'-') # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahieren der Lenkwinkel aus dem Dateinamen\n",
    "angles = np.array([int(i[-7:-4]) for i in img_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betrachtung der Verteilung der Lenkwinkel in den Trainingsdaten\n",
    "# -> typischerweise nicht symmetrisch\n",
    "pd.Series(angles, name ='angles').hist(bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spiegeln und Zusammenfügen der ungespiegelten und der gespiegelten Trainingsbilder\n",
    "# Große Bilder\n",
    "imgs_large_mirrored = imgs_large[:,:,::-1]\n",
    "print(imgs_large.shape)\n",
    "print(imgs_large_mirrored.shape)\n",
    "imgs_large_all = np.concatenate((imgs_large,imgs_large_mirrored))\n",
    "print(imgs_large_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenfügen der ungespiegelten und der gespiegelten Trainingsbilder\n",
    "# Kleine Bilder\n",
    "imgs_small_mirrored = imgs_small[:,:,::-1]\n",
    "print(imgs_small.shape)\n",
    "print(imgs_small_mirrored.shape)\n",
    "imgs_small_all = np.concatenate((imgs_small,imgs_small_mirrored))\n",
    "print(imgs_small_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spiegeln der Winkel\n",
    "angles_mirrored = [-a+180 for a in angles] \n",
    "# Kontrolle\n",
    "plt.plot(angles,angles_mirrored)\n",
    "# Zusammenführen der ungespiegelten und gespiegelten Winkel\n",
    "angles_all = np.hstack((angles,angles_mirrored)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betrachtung der Verteilung der Lenkwinkel in den Trainingsdaten mit gespiegelten Bildern\n",
    "# -> sollte symmetrisch sein, hier nicht wegen ungerader Anzahl Bins\n",
    "pd.Series(angles_all, name ='angles').hist(bins = 40)\n",
    "pd.Series(angles, name ='angles').hist(bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import notwendiger Klassen und Funktionen\n",
    "#from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Flatten,Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Trainingsdaten sollen eine Shape erhalten, welche die Farbkanäle berücksichtigen...\n",
    "# ... auch wenn in diesem Beispiele nur ein Farbkanal vorhanden ist.\n",
    "n,h,w = imgs_large_all.shape\n",
    "imgs_large_all_tf = imgs_large_all.reshape((n,h,w,1))\n",
    "n,h,w,f = imgs_large_all_tf.shape\n",
    "input_shape = (h,w,f)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen des Netzes für die großen Bilder\n",
    "# Keras Sequntial API\n",
    "model = tf.keras.Sequential(name='dnn') \n",
    "\n",
    "# Convolution Layers \n",
    "# elu: Expenential Linear Unit, similar to leaky Relu \n",
    "model.add(Conv2D(24, (5, 5), strides=(2, 2), input_shape=input_shape, activation='elu')) \n",
    "model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='elu'))\n",
    "model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='elu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu')) \n",
    "model.add(Dropout(0.2)) # more robustness \n",
    "model.add(Conv2D(64, (3, 3), activation='elu')) \n",
    "\n",
    "# Fully Connected Layers \n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.2)) # more robustness \n",
    "model.add(Dense(100, activation='elu')) \n",
    "model.add(Dense(50, activation='elu')) \n",
    "model.add(Dense(10, activation='elu'))\n",
    "\n",
    "# Output Layer: turning angle\n",
    "model.add(Dense(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überblick über das Modell\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Trainingsdaten sollen eine Shape erhalten, welche die Farbkanäle berücksichtigen...\n",
    "# ... auch wenn in diesem Beispiele nur ein Farbkanal vorhanden ist.\n",
    "# Alternative für kleines Bild\n",
    "n,h,w = imgs_small_all.shape\n",
    "imgs_small_all_tf = imgs_small_all.reshape((n,h,w,1))\n",
    "n,h,w,f = imgs_small_all_tf.shape\n",
    "input_shape_small = (h,w,f)\n",
    "print(input_shape_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative für kleinens Bild und normales NN\n",
    "model_small = tf.keras.Sequential(name='dnn_dense') \n",
    "\n",
    "# Convolution Layers \n",
    "# elu: Expenential Linear Unit, similar to leaky Relu \n",
    "model_small.add(Conv2D(10, (2, 6), strides=(2, 3), input_shape=input_shape_small, activation='elu')) \n",
    "model_small.add(Conv2D(10, (2, 5), strides=(2, 2), activation='elu'))\n",
    "model_small.add(Conv2D(10, (2, 4), strides=(2, 2), activation='elu'))\n",
    "model_small.add(Conv2D(20, (2, 2), strides=(2, 2), activation='elu'))\n",
    "# Fully Connected Layers \n",
    "model_small.add(Flatten()) \n",
    "#model_small.add(Dropout(0.2)) # more robustness \n",
    "#model_small.add(Dense(20, activation='elu')) \n",
    "model_small.add(Dense(10, activation='elu')) \n",
    "model_small.add(Dense(10, activation='elu')) \n",
    "\n",
    "# Output Layer: turning angle\n",
    "model_small.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontrolle der Architektur\n",
    "model_small.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen eines flachen Datensatzes aus den kleinen Bildern\n",
    "n,h,w = imgs_small_all.shape\n",
    "print(imgs_small_all.shape)\n",
    "imgs_small_all_tf_flat = imgs_small_all.reshape((n,h*w))\n",
    "imgs_small_all_tf_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative für kleines Bild\n",
    "# Erstellen des Netzes für das stark verkleinert Bild\n",
    "# Die Größte des Netzes muss angepasst werden. (Anzahl der Schichten, Kernelsizes, Strides)\n",
    "model_small_flat = tf.keras.Sequential(name='dnn_small') \n",
    "model_small_flat.add(Dense(100, input_shape=(imgs_small_all_tf_flat.shape), activation='elu')) \n",
    "model_small_flat.add(Dense(20, activation='elu')) \n",
    "\n",
    "# Output Layer: turning angle\n",
    "model_small_flat.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontrolle der Architektur\n",
    "# Das kleine Modell hat bedeuteten weniger Parameter\n",
    "model_small_flat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswahl der großen oder kleinen Bilder und des zugehörigen Modells\n",
    "#imgs_all_tf= imgs_small_all_tf_flat\n",
    "#model = model_small_flat\n",
    "imgs_all_tf= imgs_small_all_tf\n",
    "model = model_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontrolle und Reshapen der Trainingsdaten\n",
    "print(angles_all.shape)\n",
    "print(imgs_all_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Trainings- und Testdaten\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(imgs_all_tf, angles_all, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontrolle\n",
    "print(X_train.dtype)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_validate.dtype)\n",
    "print(X_validate.shape)\n",
    "print(X_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilieren des Modells und Wahl von Fehlerfunktion und Optimizer\n",
    "model.compile(loss ='mse', optimizer=Adam(lr=0.002))\n",
    "val_loss = []\n",
    "loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs= 50,\n",
    "    verbose=1,\n",
    "    validation_data=(X_validate,y_validate)\n",
    ")\n",
    "loss.extend(history.history['loss'])\n",
    "val_loss.extend(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellung Trainingswerte über Epochen\n",
    "skip=3\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(loss[skip:], label='Loss')\n",
    "plt.plot(val_loss[skip:], label='Validation Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss / val_loss')\n",
    "plt.legend()\n",
    "plt.title('Training - Loss Function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainings- und Testfehler\n",
    "mse_train = model.evaluate(X_train,y_train)\n",
    "mse_validate = model.evaluate(X_validate,y_validate)\n",
    "\n",
    "print('MSE train/val: {:.4f} / {:.4f}'.format(mse_train,mse_validate))\n",
    "print('RMSE train/val: {:.4f} / {:.4f}'.format(np.sqrt(mse_train),np.sqrt(mse_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Fehler\n",
    "y_train_p = model.predict(X_train)\n",
    "y_validate_p = model.predict(X_validate)\n",
    "\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.subplot(121)\n",
    "plt.plot(y_train,y_train_p,'rx',ms=2)\n",
    "plt.plot([45,135],[45,135],'k-')\n",
    "plt.xlabel('Winkel real')\n",
    "plt.ylabel('Winkel geschätzt')\n",
    "plt.title('Trainingsset')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(y_validate,y_validate_p,'bx',ms=2)\n",
    "plt.plot([45,135],[45,135],'k-')\n",
    "plt.xlabel('Winkel real')\n",
    "plt.ylabel('Winkel geschätzt')\n",
    "plt.title('Testset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des trainierten Modells\n",
    "path_to_model_file = './model/MODEL.h5'# Speichert im H5-Format\n",
    "# path_to_model_file = './model/DEMO_MODEL' # Speichert im SavedModel-Format\n",
    "model.save(path_to_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden eines Modells\n",
    "path_to_model_file = './model/MODEL.h5'\n",
    "model_loaded = tf.keras.models.load_model(path_to_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape des Input-Layers\n",
    "model_loaded.layers[0].input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainings- und Testfehler von geladenem Modell\n",
    "mse_train = model_loaded.evaluate(X_train,y_train)\n",
    "mse_validate = model_loaded.evaluate(X_validate,y_validate)\n",
    "\n",
    "print('MSE train/val: {:.4f} / {:.4f}'.format(mse_train,mse_validate))\n",
    "print('RMSE train/val: {:.4f} / {:.4f}'.format(np.sqrt(mse_train),np.sqrt(mse_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Fehler\n",
    "y_train_p = model_loaded.predict(X_train)\n",
    "y_validate_p = model_loaded.predict(X_validate)\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.subplot(121)\n",
    "plt.plot(y_train,y_train_p,'rx',ms=2)\n",
    "plt.plot([45,135],[45,135],'k-')\n",
    "plt.xlabel('Winkel real')\n",
    "plt.ylabel('Winkel geschätzt')\n",
    "plt.title('Trainingsset')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(y_validate,y_validate_p,'bx',ms=2)\n",
    "plt.plot([45,135],[45,135],'k-')\n",
    "plt.xlabel('Winkel real')\n",
    "plt.ylabel('Winkel geschätzt')\n",
    "plt.title('Testset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wahl eines Beispielbildes!\n",
    "xe = np.array( [X_train[20]] )\n",
    "print(\"Nr Bild: \", y_train[20])\n",
    "xe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittels der Methode predict\n",
    "model_loaded.predict(xe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
